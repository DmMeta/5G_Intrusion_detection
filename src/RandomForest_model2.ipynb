{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#General Imports\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from math import ceil\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rnd\n",
        "from time import perf_counter as time\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from preprocessing_utils import drop_features_, fill_nan_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-OhDfNrcCby",
        "outputId": "7dc68b15-9cd0-4826-9658-ffac40482d19"
      },
      "outputs": [],
      "source": [
        "dataset_fpath = '../data/BTS1_BTS2_fields_preserved.zip'\n",
        "nidd_dataset = pd.read_csv(dataset_fpath, compression = 'zip', low_memory=False)\n",
        "\n",
        "#Attack Type for Multi-Class Classification or Label for Binary Classification\n",
        "TARGET = 'Label'\n",
        "DROPPED_TARGET = \"Label\" if TARGET == \"Attack Type\" else \"Attack Type\"\n",
        "\n",
        "useless_features = ['Attack Tool', DROPPED_TARGET, 'Dport', 'Sport', 'SrcAddr', 'DstAddr',\"Unnamed: 0\"]\n",
        "nidd_dataset = nidd_dataset.drop(useless_features, axis=1)\n",
        "print(f\"Original shape of data: {nidd_dataset.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_dropped = {\"Nan columns\": [], \"Zero columns\": [], \"Constant columns\": [], \"General columns\": useless_features}\n",
        "preprocessing_d = {\"Time <Dropping features based on a threshold `bad` values>\": 0.,\n",
        "                   \"Filling NaNs\": 0.,\n",
        "                   \"Time <Encoding categorical features>\": 0.,\n",
        "                   \"Time <Feature selection>\": 0.}\n",
        "\n",
        "\n",
        "\n",
        "nidd_dataset_cleaned, drop_time = drop_features_(nidd_dataset,[0.95, 0.95], features_dropped)\n",
        "preprocessing_d[\"Time <Dropping features based on a threshold `bad` values>\"] = drop_time\n",
        "\n",
        "nidd_dataset_cleaned, fill_time = fill_nan_values(nidd_dataset_cleaned, method = \"mean\")\n",
        "preprocessing_d[\"Filling NaNs\"] = fill_time\n",
        "\n",
        "numeric_cols = nidd_dataset_cleaned.select_dtypes(include='number').columns\n",
        "categorical_cols = nidd_dataset_cleaned.select_dtypes(include='object').columns\n",
        "\n",
        "t0 = time()\n",
        "# Encoding categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "for column in categorical_cols:\n",
        "    nidd_dataset_cleaned[column] = label_encoder.fit_transform(nidd_dataset_cleaned[column])\n",
        "\n",
        "t1 = time()\n",
        "preprocessing_d[\"Time <Encoding categorical features>\"] = t1 - t0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "feature_extraction_model = RandomForestClassifier(random_state= rnd.seed(42))\n",
        "feature_extraction_model.fit(nidd_dataset_cleaned.iloc[:,:-1], nidd_dataset_cleaned[TARGET])\n",
        "\n",
        "print(f\"Feature importance: {feature_extraction_model.feature_importances_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances_ = pd.DataFrame({'Feature': nidd_dataset_cleaned.iloc[:,:-1].columns, \n",
        "                                    'Importance': feature_extraction_model.feature_importances_})\n",
        "\n",
        "# print(f\"Feature importance: {feature_importances_}\")\n",
        "# Bar Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', \n",
        "            data=feature_importances_.sort_values(by='Importance', ascending=False),\n",
        "            width = 1.2, gap = 0.4,\n",
        "            color = \"darkviolet\")\n",
        "plt.title('Feature Importances - Bar Plot')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Applying Z-normalization to the selected features, training a RandomForest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "lA6QfmD8gNyE",
        "outputId": "c472ce9a-a7a2-4516-bff2-99c9edec9e99"
      },
      "outputs": [],
      "source": [
        "\n",
        "top_10_features_cols = feature_importances_.sort_values(by='Importance', ascending=False).head(10)['Feature'].values\n",
        "print(top_10_features_cols)\n",
        "target = nidd_dataset_cleaned[TARGET]\n",
        "features = nidd_dataset[top_10_features_cols]\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=rnd.seed(42)) \n",
        "\n",
        "numeric_features = list(set(numeric_cols) & set(top_10_features_cols))\n",
        "categorical_features = list(set(categorical_cols) & set(top_10_features_cols))\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')), \n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "        \n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in categorical_features:\n",
        "    X_test[column] = label_encoder.fit_transform(X_test[column])\n",
        "\n",
        "model = pipeline.named_steps[\"classifier\"]\n",
        "print(model)\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Confusion Matrix and classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "target_categories = set(nidd_dataset[TARGET])\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(conf_matrix, cmap=plt.cm.Blues, interpolation='nearest')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(ticks=np.arange(len(target_categories)), labels=target_categories, rotation=45)\n",
        "plt.yticks(ticks=np.arange(len(target_categories)), labels=target_categories)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, format(conf_matrix[i, j], 'd'), ha=\"center\", va=\"center\", color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "class_report = classification_report(y_test, predictions, target_names=target_categories , digits=6)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "for key, time in preprocessing_d.items():\n",
        "    print(f\"{key}: {time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib \n",
        "from pprint import pprint as pp\n",
        "import pickle\n",
        "\n",
        "parameters = pipeline.named_steps['classifier']\n",
        "print(type(parameters))\n",
        "# pickle.dump(top_10_features_cols, open('top_10_features_cols.pkl', 'wb'))\n",
        "# joblib.dump(parameters, '../models/RandomForest.pkl')\n",
        "# pickle.dump(label_encoder, open('label_encoderBinary.pkl', 'wb'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
